{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {
    "id": "7fb27b941602401d91542211134fc71a"
   },
   "source": [
    "# Muon Optimizer: Accelerating Grokking Reproduction\n",
    "\n",
    "This notebook demonstrates the Muon optimizer and its ability to accelerate the grokking phenomenon compared to AdamW.\n",
    "\n",
    "## What is Muon?\n",
    "\n",
    "Muon is an optimizer that combines:\n",
    "1. **Spectral norm constraints** for better optimization landscapes\n",
    "2. **Orthogonalized gradients** for improved convergence\n",
    "3. **Second-order information** for smarter parameter updates\n",
    "\n",
    "**Key Results:**\n",
    "- 33% faster grokking (153 ‚Üí 103 epochs average)\n",
    "- Statistically significant improvement across 7 modular arithmetic tasks\n",
    "- Better path from memorization to generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {
    "id": "acae54e37e7d407bbb7b55eff062a284"
   },
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {
    "id": "9a63283cbaf04dbcab1f6479b197f3a8"
   },
   "outputs": [],
   "source": [
    "! [ ! -d \"muon\" ] && git clone https://github.com/bangyen/muon.git\n",
    "! cd muon && pip install -e .\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"./muon\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {
    "id": "8dd0d8092fe74a7c96281538738b07e2"
   },
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c4552",
   "metadata": {
    "id": "0e0c4552"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import Muon optimizer\n",
    "from muon import SingleDeviceMuonWithAuxAdam\n",
    "\n",
    "# Import local modules\n",
    "from src.dataset import DatasetConfig, ModularArithmeticDataset\n",
    "from src.model import GrokkingTransformer, ModelConfig\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2119b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_EPOCHS = 50  # Reduced for quick demo\n",
    "BATCH_SIZE = 32\n",
    "MIN_DIMENSIONS = 2  # Minimum dimensions for hidden weights\n",
    "GROKKING_THRESHOLD = 95.0  # Accuracy threshold for grokking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {
    "id": "8edb47106e1a46a883d545849b8ab81b"
   },
   "source": [
    "## ZSharp vs SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {
    "id": "10185d26023b46108eb7d9f57d49d2b3"
   },
   "outputs": [],
   "source": [
    "def quick_grokking_demo():\n",
    "    \"\"\"Quick demonstration of Muon vs AdamW on modular addition\"\"\"\n",
    "    print(\"Muon vs AdamW Grokking Demo\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Create dataset for modular addition (simplest task)\n",
    "    dataset_config = DatasetConfig(\n",
    "        task_type=\"add\", modulus=97, train_split=0.8\n",
    "    )\n",
    "    dataset = ModularArithmeticDataset(dataset_config)\n",
    "\n",
    "    # Create model\n",
    "    model_config = ModelConfig(\n",
    "        vocab_size=dataset.vocab_size,\n",
    "        hidden_size=128,\n",
    "        num_layers=4,\n",
    "        num_heads=8,\n",
    "        ff_size=512,\n",
    "    )\n",
    "\n",
    "    # Create two identical models\n",
    "    model_muon = GrokkingTransformer(model_config).to(device)\n",
    "    model_adamw = GrokkingTransformer(model_config).to(device)\n",
    "\n",
    "    # Copy weights to ensure identical starting points\n",
    "    model_adamw.load_state_dict(model_muon.state_dict())\n",
    "\n",
    "    # Create optimizers\n",
    "    # Muon optimizer with proper parameter grouping\n",
    "    hidden_weights = [\n",
    "        p for p in model_muon.parameters() if p.ndim >= MIN_DIMENSIONS\n",
    "    ]\n",
    "    other_params = [\n",
    "        p for p in model_muon.parameters() if p.ndim < MIN_DIMENSIONS\n",
    "    ]\n",
    "\n",
    "    param_groups_muon = [\n",
    "        dict(params=hidden_weights, use_muon=True, lr=0.02, weight_decay=1e-2),\n",
    "        dict(\n",
    "            params=other_params,\n",
    "            use_muon=False,\n",
    "            lr=0.002,\n",
    "            betas=(0.9, 0.95),\n",
    "            weight_decay=1e-2,\n",
    "        ),\n",
    "    ]\n",
    "    optimizer_muon = SingleDeviceMuonWithAuxAdam(param_groups_muon)\n",
    "\n",
    "    # AdamW optimizer\n",
    "    optimizer_adamw = torch.optim.AdamW(\n",
    "        model_adamw.parameters(), lr=0.001, weight_decay=1e-2\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding tokens\n",
    "\n",
    "    # Training loop\n",
    "    print(f\"Training for {MAX_EPOCHS} epochs...\")\n",
    "\n",
    "    muon_grokking_epoch = None\n",
    "    adamw_grokking_epoch = None\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        # Train Muon model\n",
    "        model_muon.train()\n",
    "        muon_loss = 0\n",
    "        muon_correct = 0\n",
    "        muon_total = 0\n",
    "\n",
    "        # Get validation data and process in batches\n",
    "        val_data = dataset.get_val_data()[:BATCH_SIZE]\n",
    "\n",
    "        # Stack individual samples into batches\n",
    "        input_batch = torch.stack([sample[\"input\"] for sample in val_data]).to(\n",
    "            device\n",
    "        )\n",
    "        target_batch = torch.stack(\n",
    "            [sample[\"target\"] for sample in val_data]\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer_muon.zero_grad()\n",
    "        outputs = model_muon(input_batch)\n",
    "        loss = criterion(\n",
    "            outputs.view(-1, outputs.size(-1)), target_batch.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer_muon.step()\n",
    "\n",
    "        muon_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, -1)\n",
    "        muon_total += target_batch.numel()\n",
    "        muon_correct += (predicted == target_batch).sum().item()\n",
    "\n",
    "        muon_acc = 100 * muon_correct / muon_total\n",
    "\n",
    "        # Train AdamW model\n",
    "        model_adamw.train()\n",
    "        adamw_loss = 0\n",
    "        adamw_correct = 0\n",
    "        adamw_total = 0\n",
    "\n",
    "        optimizer_adamw.zero_grad()\n",
    "        outputs = model_adamw(input_batch)\n",
    "        loss = criterion(\n",
    "            outputs.view(-1, outputs.size(-1)), target_batch.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer_adamw.step()\n",
    "\n",
    "        adamw_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, -1)\n",
    "        adamw_total += target_batch.numel()\n",
    "        adamw_correct += (predicted == target_batch).sum().item()\n",
    "\n",
    "        adamw_acc = 100 * adamw_correct / adamw_total\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1:2d}: Muon Acc: {muon_acc:5.1f}%, AdamW Acc: {adamw_acc:5.1f}%\"\n",
    "        )\n",
    "\n",
    "        # Check for grokking (95% accuracy threshold)\n",
    "        if muon_grokking_epoch is None and muon_acc >= GROKKING_THRESHOLD:\n",
    "            muon_grokking_epoch = epoch + 1\n",
    "            print(f\"üéâ Muon grokked at epoch {muon_grokking_epoch}!\")\n",
    "\n",
    "        if adamw_grokking_epoch is None and adamw_acc >= GROKKING_THRESHOLD:\n",
    "            adamw_grokking_epoch = epoch + 1\n",
    "            print(f\"üéâ AdamW grokked at epoch {adamw_grokking_epoch}!\")\n",
    "\n",
    "    # Results\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"Muon grokking epoch:   {muon_grokking_epoch or 'Not achieved'}\")\n",
    "    print(f\"AdamW grokking epoch:  {adamw_grokking_epoch or 'Not achieved'}\")\n",
    "\n",
    "    if muon_grokking_epoch and adamw_grokking_epoch:\n",
    "        speedup = adamw_grokking_epoch / muon_grokking_epoch\n",
    "        print(f\"Speedup: {speedup:.2f}x faster with Muon\")\n",
    "    elif muon_grokking_epoch:\n",
    "        print(\"‚úÖ Muon achieved grokking, AdamW did not\")\n",
    "    elif adamw_grokking_epoch:\n",
    "        print(\"‚ùå AdamW achieved grokking, Muon did not\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Neither optimizer achieved grokking in this quick demo\")\n",
    "\n",
    "\n",
    "# Run the demo\n",
    "quick_grokking_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {
    "id": "8763a12b2bbd4a93a75aff182afb95dc"
   },
   "source": [
    "## Key Takeaways\n",
    "\n",
    "This demo shows how Muon accelerates grokking:\n",
    "\n",
    "1. **Faster Convergence**: Muon typically reaches grokking in fewer epochs than AdamW\n",
    "2. **Better Optimization**: Spectral norm constraints and orthogonalized gradients improve the optimization landscape\n",
    "3. **Grokking Phenomenon**: Models transition from memorization to true understanding\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Run full experiments: `make run-experiments`\n",
    "- Try different tasks: `python -m scripts.train_tasks --single_task`\n",
    "- Analyze results: `make analyze`\n",
    "\n",
    "For more information, see the [GitHub repository](https://github.com/bangyen/muon) and the [original paper](https://arxiv.org/abs/2504.16041)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
